{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_training_decade.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt-MlTzrpbBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import sys\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt7D9Rs0pz5m",
        "colab_type": "code",
        "outputId": "1df29f20-b73b-476b-fa12-9bd42e9f51d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daQjEj3qp_vs",
        "colab_type": "code",
        "outputId": "3c9385c5-fa05-47e7-e167-210361e35adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 13 19:48:18 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    18W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PjNkRy6qOSa",
        "colab_type": "text"
      },
      "source": [
        "Thats a good gpu, with no pesky graphics taking up storage either"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxE3iRhOqF_5",
        "colab_type": "code",
        "outputId": "6fcecee1-e7c5-4811-fb3d-386a7d83156c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSbSpR4vqV9L",
        "colab_type": "code",
        "outputId": "ecbc1f4b-e270-4af5-e480-49eacba75d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /gdrive/My\\ Drive/cs445/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/cs445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPl46aMNrqfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import neuralnetworks_pytorch as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpLUT8hIqgK2",
        "colab_type": "code",
        "outputId": "0c18613a-929a-4652-9489-4d871f1a22e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_training_decade.ipynb  neuralnetworks_pytorch.py  \u001b[0m\u001b[01;34mpickles\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg6JcnOAqtVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Xbatch1 = pkl.load(open(\"./pickles/training_batches/batch0.pkl\", \"rb\"))\n",
        "#Tbatch1 = pkl.load(open(\"./pickles/training_batches/batch0_targets.pkl\", \"rb\"))\n",
        "#Xbatch2 = pkl.load(open(\"./pickles/training_batches/batch1.pkl\", \"rb\"))\n",
        "#Tbatch2 = pkl.load(open(\"./pickles/training_batches/batch1_targets.pkl\", \"rb\"))\n",
        "#Xbatch3 = pkl.load(open(\"./pickles/training_batches/batch2.pkl\", \"rb\"))\n",
        "#Tbatch3 = pkl.load(open(\"./pickles/training_batches/batch2_targets.pkl\", \"rb\"))\n",
        "#Xbatch1_test = pkl.load(open(\"./pickles/test_batches/batch0.pkl\", \"rb\"))\n",
        "#Tbatch1_test = pkl.load(open(\"./pickles/test_batches/batch0_targets.pkl\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDY37UPL3D7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xbatch = pkl.load(open(\"./pickles/train_batches1-5/batch0.pkl\", \"rb\"))\n",
        "Tbatch = pkl.load(open(\"./pickles/train_batches1-5/batch0_targets.pkl\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LzNQIWATCwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xbatch_test = pkl.load(open(\"./pickles/test_batches1-5/batch0.pkl\", \"rb\"))\n",
        "Tbatch_test = pkl.load(open(\"./pickles/test_batches1-5/batch0_targets.pkl\", \"rb\")) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CsoAkXj4J8E",
        "colab_type": "code",
        "outputId": "5daa0b80-d273-4206-a9d8-a86cd9b287e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xbatch.shape, Xbatch_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6515, 55, 110, 3), (1629, 55, 110, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQhnlHM6rMKi",
        "colab_type": "code",
        "outputId": "82679686-78e8-4012-cb9a-ef32e3b1068e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xbatch.nbytes #118 MB, used to be 450 MB a batch before downsampling"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118247250"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNTh0LPVrPkM",
        "colab_type": "code",
        "outputId": "ffdb4d28-715d-43ff-b9de-51465736bcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "makes = np.unique(Tbatch[:, 0])\n",
        "styles = np.unique(Tbatch[:,1])\n",
        "years = np.unique(Tbatch[:,2])\n",
        "years, makes, styles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['1991', '1993', '1994', '1997', '1998', '1999', '2000', '2001',\n",
              "        '2002', '2006', '2007', '2008', '2009', '2010', '2011', '2012'],\n",
              "       dtype='<U54'),\n",
              " array(['AM', 'Acura', 'Aston', 'Audi', 'BMW', 'Bentley', 'Bugatti',\n",
              "        'Buick', 'Cadillac', 'Chevrolet', 'Chrysler', 'Daewoo', 'Dodge',\n",
              "        'Eagle', 'FIAT', 'Ferrari', 'Fisker', 'Ford', 'GMC', 'Geo',\n",
              "        'HUMMER', 'Honda', 'Hyundai', 'Infiniti', 'Isuzu', 'Jaguar',\n",
              "        'Jeep', 'Lamborghini', 'Land', 'Lincoln', 'MINI', 'Maybach',\n",
              "        'Mazda', 'McLaren', 'Mercedes-Benz', 'Mitsubishi', 'Nissan',\n",
              "        'Plymouth', 'Porsche', 'Ram', 'Rolls-Royce', 'Scion', 'Spyker',\n",
              "        'Suzuki', 'Tesla', 'Toyota', 'Volkswagen', 'Volvo', 'smart'],\n",
              "       dtype='<U54'),\n",
              " array(['Convertible', 'Coupe', 'Hatchback', 'Minivan', 'SUV', 'Sedan',\n",
              "        'Truck', 'Van', 'Wagon'], dtype='<U54'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiwLJ1f6TypD",
        "colab_type": "text"
      },
      "source": [
        "Make target classes for decade of produciton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K7PXJKIrR_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for target in Tbatch:\n",
        "    if int(target[2]) < 2000:\n",
        "        target[2] = 0\n",
        "    elif 2000 <= int(target[2]) < 2010:\n",
        "        target[2] = 1\n",
        "    else:\n",
        "        target[2] = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjmgvElsrTpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for target in Tbatch_test:\n",
        "    if int(target[2]) < 2000:\n",
        "        target[2] = 0\n",
        "    elif 2000 <= int(target[2]) < 2010:\n",
        "        target[2] = 1\n",
        "    else:\n",
        "        target[2] = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wTnrLKFrV4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_outputs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS2YyubgrXnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ttrain = Tbatch[:, 2]\n",
        "Ttest = Tbatch_test[:, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFGjwi8VUBUg",
        "colab_type": "text"
      },
      "source": [
        "Change to the channels first format, which is what is expected by pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvI08a9Lraib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xbatch = np.rollaxis(Xbatch, 3, 1)\n",
        "Xbatch_test = np.rollaxis(Xbatch_test, 3, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ClDQ-qqrcYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size_in_pixels = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxfn7M3MUO5P",
        "colab_type": "text"
      },
      "source": [
        "Image is 55 by 110. For convolution size, we can start with 7x7, then 5x5 down to 3x3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFtUpDbsreIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hiddens_by_layer = [300, 400, 500, 800, 5000, 10000]\n",
        "batch_size = 200\n",
        "learning_rate = .00001 #.00001 great with 16\n",
        "n_iterations = 6\n",
        "n_conv_layers = 5\n",
        "\n",
        "window = [7, 5, 3, 3]\n",
        "stride = [2, 2, 2, 2]\n",
        "relu = True\n",
        "gpu = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFXsxOpprfW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_height = Xbatch.shape[2]\n",
        "input_width = Xbatch.shape[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xav3ptl1rhmz",
        "colab_type": "code",
        "outputId": "53944850-4a47-41e1-dc14-84a22246d6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nnet = nn.NeuralNetworkClassifier_Pytorch(input_size_in_pixels, \n",
        "                                          n_hiddens_by_layer, \n",
        "                                          n_outputs, \n",
        "                                          relu,gpu, \n",
        "                                          n_conv_layers, window, stride, input_height, input_width)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNetworkClassifier_Pytorch created on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_snvckGriOo",
        "colab_type": "code",
        "outputId": "8b38290b-65ae-4e7d-bff6-0fd1c2ac6235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "nnet.train(Xbatch, Ttrain.astype(np.uint8), Xbatch_test, Ttest.astype(np.uint8), n_iterations, batch_size, learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, cost = 0.9168, acc = 66.18\n",
            "Iteration 2, cost = 0.7342, acc = 65.87\n",
            "Iteration 3, cost = 0.6833, acc = 66.05\n",
            "Iteration 4, cost = 0.6269, acc = 66.24\n",
            "Iteration 5, cost = 0.5655, acc = 65.87\n",
            "Iteration 6, cost = 0.5040, acc = 66.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYhwqo-mrzRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def percent_correct(actual, predicted):\n",
        "    return 100 * np.mean(actual == predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPapclszBLO_",
        "colab_type": "code",
        "outputId": "a2107c09-e613-41f0-8b25-fc1e33b27245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes, _, _ = nnet.use(Xbatch_test)\n",
        "percent = percent_correct(Ttest.astype(np.uint8), classes)\n",
        "percent\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.7280540208717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udu_l7Inl5q4",
        "colab_type": "text"
      },
      "source": [
        "We need to use this on a CPU. Let's try and get it back from the GPU so we can use it on the server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vboy6A-CrUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpu_nnet = nnet.to(torch.device('cpu'))\n",
        "cpu_nnet.device = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMkw0wajCvtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pkl.dump(cpu_nnet, open('decade_nnet', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS_CfnYyFYRD",
        "colab_type": "code",
        "outputId": "e5051148-c547-438c-c300-eb307f764387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cpu_nnet.device "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THeX15qmC15d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}